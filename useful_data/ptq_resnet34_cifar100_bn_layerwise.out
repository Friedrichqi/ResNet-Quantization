Accuracy of the original FP32 model: 68.36%
Accuracy of the bn layer1 quantized model (8-bit): 68.37%
Accuracy of the bn layer1 quantized model (7-bit): 68.33%
Accuracy of the bn layer1 quantized model (6-bit): 66.60%
Accuracy of the bn layer1 quantized model (5-bit): 67.13%
Accuracy of the bn layer1 quantized model (4-bit): 65.36%
Accuracy of the bn layer1 quantized model (3-bit): 54.97%
Accuracy of the bn layer1 quantized model (2-bit): 47.77%
Accuracy of the bn layer1 quantized model (1-bit): 18.14%
Accuracy of the bn layer2 quantized model (8-bit): 68.07%
Accuracy of the bn layer2 quantized model (7-bit): 65.77%
Accuracy of the bn layer2 quantized model (6-bit): 65.07%
Accuracy of the bn layer2 quantized model (5-bit): 59.69%
Accuracy of the bn layer2 quantized model (4-bit): 56.42%
Accuracy of the bn layer2 quantized model (3-bit): 10.21%
Accuracy of the bn layer2 quantized model (2-bit): 9.73%
Accuracy of the bn layer2 quantized model (1-bit): 1.00%
Accuracy of the bn layer3 quantized model (8-bit): 65.11%
Accuracy of the bn layer3 quantized model (7-bit): 61.38%
Accuracy of the bn layer3 quantized model (6-bit): 62.64%
Accuracy of the bn layer3 quantized model (5-bit): 40.80%
Accuracy of the bn layer3 quantized model (4-bit): 41.25%
Accuracy of the bn layer3 quantized model (3-bit): 2.17%
Accuracy of the bn layer3 quantized model (2-bit): 1.00%
Accuracy of the bn layer3 quantized model (1-bit): 1.00%
Accuracy of the bn layer4 quantized model (8-bit): 67.73%
Accuracy of the bn layer4 quantized model (7-bit): 65.23%
Accuracy of the bn layer4 quantized model (6-bit): 65.11%
Accuracy of the bn layer4 quantized model (5-bit): 62.91%
Accuracy of the bn layer4 quantized model (4-bit): 62.62%
Accuracy of the bn layer4 quantized model (3-bit): 37.32%
Accuracy of the bn layer4 quantized model (2-bit): 37.30%
Accuracy of the bn layer4 quantized model (1-bit): 1.00%
