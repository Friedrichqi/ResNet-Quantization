Accuracy of the original FP32 model: 92.09%
Accuracy of the bn layer1 quantized model (8-bit): 92.08%
Accuracy of the bn layer1 quantized model (7-bit): 92.02%
Accuracy of the bn layer1 quantized model (6-bit): 91.86%
Accuracy of the bn layer1 quantized model (5-bit): 91.63%
Accuracy of the bn layer1 quantized model (4-bit): 70.09%
Accuracy of the bn layer1 quantized model (3-bit): 48.98%
Accuracy of the bn layer1 quantized model (2-bit): 10.00%
Accuracy of the bn layer1 quantized model (1-bit): 10.00%
Accuracy of the bn layer2 quantized model (8-bit): 92.03%
Accuracy of the bn layer2 quantized model (7-bit): 92.09%
Accuracy of the bn layer2 quantized model (6-bit): 92.18%
Accuracy of the bn layer2 quantized model (5-bit): 92.13%
Accuracy of the bn layer2 quantized model (4-bit): 89.38%
Accuracy of the bn layer2 quantized model (3-bit): 80.96%
Accuracy of the bn layer2 quantized model (2-bit): 10.01%
Accuracy of the bn layer2 quantized model (1-bit): 10.00%
Accuracy of the bn layer3 quantized model (8-bit): 92.10%
Accuracy of the bn layer3 quantized model (7-bit): 92.07%
Accuracy of the bn layer3 quantized model (6-bit): 92.05%
Accuracy of the bn layer3 quantized model (5-bit): 92.01%
Accuracy of the bn layer3 quantized model (4-bit): 90.37%
Accuracy of the bn layer3 quantized model (3-bit): 85.88%
Accuracy of the bn layer3 quantized model (2-bit): 16.23%
Accuracy of the bn layer3 quantized model (1-bit): 10.00%
Accuracy of the bn layer4 quantized model (8-bit): 92.10%
Accuracy of the bn layer4 quantized model (7-bit): 92.11%
Accuracy of the bn layer4 quantized model (6-bit): 92.13%
Accuracy of the bn layer4 quantized model (5-bit): 92.15%
Accuracy of the bn layer4 quantized model (4-bit): 90.09%
Accuracy of the bn layer4 quantized model (3-bit): 87.63%
Accuracy of the bn layer4 quantized model (2-bit): 10.08%
Accuracy of the bn layer4 quantized model (1-bit): 10.00%
